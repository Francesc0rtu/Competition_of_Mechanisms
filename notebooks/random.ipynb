{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../data')\n",
    "from src.model import WrapHookedTransformer\n",
    "from src.dataset import TlensDataset\n",
    "from src.experiment import LogitAttribution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Dataset loaded from ../data/full_data_sampled_gpt2.json\n",
      "Number of samples: 100\n"
     ]
    }
   ],
   "source": [
    "model = WrapHookedTransformer.from_pretrained(\"gpt2\")\n",
    "dataset = TlensDataset(\"../data/full_data_sampled_gpt2.json\", model, slice=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit, cache = model.run_with_cache(\"ciao come va?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_124729/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2483060629.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_124729/2483060629.py'</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Hooked</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1917</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">all_composition_scores</span>                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1914 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1915 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"mode must be one of ['Q', 'K', 'V'] not {</span>mode<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1916 │   │   </span>                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1917 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>scores = utils.composition_scores(left, right, broadcast_dims=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1918 │   │   # Mask scores to be zero for all pairs with the right head in the same lay</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1919 │   │   </span>mask = (                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1920 │   │   │   </span>torch.arange(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cfg.n_layers, device=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cfg.device)[:, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">695</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">composition_scores</span>                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 692 │   </span>left = left.collapse_l()                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 693 │   </span>r_norms = right.norm(dim=[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 694 │   </span>l_norms = left.norm(dim=[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 695 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>comp_norms = (left @ right).norm(dim=[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 696 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> comp_norms / r_norms / l_norms                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 697 </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 698 </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.80</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.81</span> GiB total \n",
       "capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">977.51</span> MiB already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.81</span> GiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.01</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span>\n",
       "If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid \n",
       "fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭─\u001b[0m\u001b[91m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[91m ───────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/tmp/ipykernel_124729/\u001b[0m\u001b[1;33m2483060629.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                         \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_124729/2483060629.py'\u001b[0m                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mHooked\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33mTransformer.py\u001b[0m:\u001b[94m1917\u001b[0m in \u001b[92mall_composition_scores\u001b[0m                                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1914 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1915 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmode must be one of [\u001b[0m\u001b[33m'\u001b[0m\u001b[33mQ\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33mK\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33mV\u001b[0m\u001b[33m'\u001b[0m\u001b[33m] not \u001b[0m\u001b[33m{\u001b[0mmode\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1916 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m1917 \u001b[2m│   │   \u001b[0mscores = utils.composition_scores(left, right, broadcast_dims=\u001b[94mTrue\u001b[0m)        \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1918 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Mask scores to be zero for all pairs with the right head in the same lay\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1919 \u001b[0m\u001b[2m│   │   \u001b[0mmask = (                                                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1920 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.arange(\u001b[96mself\u001b[0m.cfg.n_layers, device=\u001b[96mself\u001b[0m.cfg.device)[:, \u001b[94mNone\u001b[0m, \u001b[94mNone\u001b[0m, \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mutils.\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m695\u001b[0m in \u001b[92mcomposition_scores\u001b[0m                                                              \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 692 \u001b[0m\u001b[2m│   \u001b[0mleft = left.collapse_l()                                                       \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 693 \u001b[0m\u001b[2m│   \u001b[0mr_norms = right.norm(dim=[-\u001b[94m2\u001b[0m, -\u001b[94m1\u001b[0m])                                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 694 \u001b[0m\u001b[2m│   \u001b[0ml_norms = left.norm(dim=[-\u001b[94m2\u001b[0m, -\u001b[94m1\u001b[0m])                                              \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m 695 \u001b[2m│   \u001b[0mcomp_norms = (left @ right).norm(dim=[-\u001b[94m2\u001b[0m, -\u001b[94m1\u001b[0m])                                 \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 696 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m comp_norms / r_norms / l_norms                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 697 \u001b[0m                                                                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 698 \u001b[0m                                                                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m3.80\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m3.81\u001b[0m GiB total \n",
       "capacity; \u001b[1;36m977.51\u001b[0m MiB already allocated; \u001b[1;36m1.81\u001b[0m GiB free; \u001b[1;36m1.01\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m\n",
       "If reserved memory is >> allocated memory try setting max_split_size_mb to avoid \n",
       "fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.all_composition_scores(mode=\"V\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
