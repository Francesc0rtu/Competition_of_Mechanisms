{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../data')\n",
    "from src.model import WrapHookedTransformer\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = WrapHookedTransformer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_43241/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2318662754.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_43241/2318662754.py'</span>                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Hooked</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">552</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_with_cache</span>                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 549 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">ActivationCache object, with a bunch of useful HookedTransformer specific </span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 550 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dictionary of activations as in HookedRootModule.</span>                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 551 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 552 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>out, cache_dict = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().run_with_cache(                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 553 │   │   │   </span>*model_args, remove_batch_dim=remove_batch_dim, **kwargs               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 554 │   │   </span>)                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 555 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_cache_object:                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hook_p</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">oints.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">481</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_with_cache</span>                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">478 │   │   │   </span>reset_hooks_end=reset_hooks_end,                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">479 │   │   │   </span>clear_contexts=clear_contexts,                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">480 │   │   </span>):                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>481 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_out = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>(*model_args, **model_kwargs)                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> incl_bwd:                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 │   │   │   │   </span>model_out.backward()                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484 </span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Hooked</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Transformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">480</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 477 │   │   │   │   │   │   </span>devices.get_device_for_block_index(i, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cfg)            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 478 │   │   │   │   │   </span>)                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 479 │   │   │   │   </span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 480 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>residual = block(                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 481 │   │   │   │   │   </span>residual,                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 482 │   │   │   │   │   </span>past_kv_cache_entry=past_kv_cache[i]                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 483 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_kv_cache <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">compon</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ents.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1043</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1040 │   │   │   # hook the residual stream states that are used to calculate the</span>       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1041 │   │   │   # queries, keys and values, independently.</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042 │   │   │   # Then take the layer norm of these inputs, and pass these to the atte</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1043 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn(                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1044 │   │   │   │   </span>query_input=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln1(query_input)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1045 │   │   │   │   </span>+ (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> shortformer_pos_embed <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> shortformer_pos_embed <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046 │   │   │   │   </span>key_input=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln1(key_input)                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">compon</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ents.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">550</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 547 │   │   │   </span>qkv_einops_string = <span style=\"color: #808000; text-decoration-color: #808000\">\"batch pos d_model\"</span>                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 548 │   │   </span>                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 549 │   │   </span>q = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.hook_q(                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 550 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>einsum(                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 551 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>qkv_einops_string<span style=\"color: #808000; text-decoration-color: #808000\">}, head_index d_model d_head \\</span>                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 552 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">-&gt; batch pos head_index d_head\"</span>,                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 553 │   │   │   │   </span>query_input,                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/fancy_einsum/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.p</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">136</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">einsum</span>                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   </span>backend = get_backend(operands[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   </span>new_equation = convert_equation(equation)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>136 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> backend.einsum(new_equation, *operands)                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/fancy_einsum/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.p</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">einsum</span>                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 51 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(tensor, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.torch.Tensor)                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 52 │   </span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">einsum</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, equation, *operands):                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.torch.einsum(equation, *operands)                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 </span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 56 </span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">NumpyBackend</span>(AbstractBackend):                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">378</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">einsum</span>                                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(operands) &lt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> opt_einsum.enabled:                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 376 │   │   # the path for contracting 0 or 1 time(s) is already optimized</span>             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 377 │   │   # or the user has disabled using opt_einsum</span>                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 378 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _VF.einsum(equation, operands)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[attr-defined]</span>        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 379 │   </span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 380 │   </span>path = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 381 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> opt_einsum.is_available():                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">cublasCreate</span><span style=\"font-weight: bold\">(</span>handle<span style=\"font-weight: bold\">)</span>`\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭─\u001b[0m\u001b[91m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[91m ───────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/tmp/ipykernel_43241/\u001b[0m\u001b[1;33m2318662754.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_43241/2318662754.py'\u001b[0m                 \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mHooked\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33mTransformer.py\u001b[0m:\u001b[94m552\u001b[0m in \u001b[92mrun_with_cache\u001b[0m                                                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 549 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mActivationCache object, with a bunch of useful HookedTransformer specific \u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 550 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mdictionary of activations as in HookedRootModule.\u001b[0m                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 551 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                        \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m 552 \u001b[2m│   │   \u001b[0mout, cache_dict = \u001b[96msuper\u001b[0m().run_with_cache(                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 553 \u001b[0m\u001b[2m│   │   │   \u001b[0m*model_args, remove_batch_dim=remove_batch_dim, **kwargs               \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 554 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 555 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m return_cache_object:                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mhook_p\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33moints.py\u001b[0m:\u001b[94m481\u001b[0m in \u001b[92mrun_with_cache\u001b[0m                                                            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m478 \u001b[0m\u001b[2m│   │   │   \u001b[0mreset_hooks_end=reset_hooks_end,                                        \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m479 \u001b[0m\u001b[2m│   │   │   \u001b[0mclear_contexts=clear_contexts,                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m480 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m481 \u001b[2m│   │   │   \u001b[0mmodel_out = \u001b[96mself\u001b[0m(*model_args, **model_kwargs)                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m incl_bwd:                                                            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m483 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_out.backward()                                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m484 \u001b[0m                                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mHooked\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33mTransformer.py\u001b[0m:\u001b[94m480\u001b[0m in \u001b[92mforward\u001b[0m                                                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 477 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mdevices.get_device_for_block_index(i, \u001b[96mself\u001b[0m.cfg)            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 478 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                              \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 479 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m 480 \u001b[2m│   │   │   │   \u001b[0mresidual = block(                                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 481 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mresidual,                                                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 482 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpast_kv_cache_entry=past_kv_cache[i]                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 483 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m past_kv_cache \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mcompon\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33ments.py\u001b[0m:\u001b[94m1043\u001b[0m in \u001b[92mforward\u001b[0m                                                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1040 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# hook the residual stream states that are used to calculate the\u001b[0m       \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1041 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# queries, keys and values, independently.\u001b[0m                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1042 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Then take the layer norm of these inputs, and pass these to the atte\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m1043 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.attn(                                                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1044 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mquery_input=\u001b[96mself\u001b[0m.ln1(query_input)                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1045 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m+ (\u001b[94m0.0\u001b[0m \u001b[94mif\u001b[0m shortformer_pos_embed \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m shortformer_pos_embed \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1046 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mkey_input=\u001b[96mself\u001b[0m.ln1(key_input)                                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/transformer_lens/\u001b[0m\u001b[1;33mcompon\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33ments.py\u001b[0m:\u001b[94m550\u001b[0m in \u001b[92mforward\u001b[0m                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 547 \u001b[0m\u001b[2m│   │   │   \u001b[0mqkv_einops_string = \u001b[33m\"\u001b[0m\u001b[33mbatch pos d_model\u001b[0m\u001b[33m\"\u001b[0m                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 548 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 549 \u001b[0m\u001b[2m│   │   \u001b[0mq = \u001b[96mself\u001b[0m.hook_q(                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m 550 \u001b[2m│   │   │   \u001b[0meinsum(                                                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 551 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mqkv_einops_string\u001b[33m}\u001b[0m\u001b[33m, head_index d_model d_head \u001b[0m\u001b[33m\\\u001b[0m                 \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 552 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33m-> batch pos head_index d_head\u001b[0m\u001b[33m\"\u001b[0m,                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 553 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mquery_input,                                                       \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/fancy_einsum/\u001b[0m\u001b[1;33m__init__.p\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m136\u001b[0m in \u001b[92meinsum\u001b[0m                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   \u001b[0mbackend = get_backend(operands[\u001b[94m0\u001b[0m])                                              \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   \u001b[0mnew_equation = convert_equation(equation)                                       \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m136 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m backend.einsum(new_equation, *operands)                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/fancy_einsum/\u001b[0m\u001b[1;33m__init__.p\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m54\u001b[0m in \u001b[92meinsum\u001b[0m                                                                            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96misinstance\u001b[0m(tensor, \u001b[96mself\u001b[0m.torch.Tensor)                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   \u001b[0m                                                                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92meinsum\u001b[0m(\u001b[96mself\u001b[0m, equation, *operands):                                          \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.torch.einsum(equation, *operands)                               \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 55 \u001b[0m                                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 56 \u001b[0m                                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mNumpyBackend\u001b[0m(AbstractBackend):                                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[2;33m/home/francesco/anaconda3/envs/torch/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m378\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m in \u001b[92meinsum\u001b[0m                                                                                 \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                                                                           \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(operands) <= \u001b[94m2\u001b[0m \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m opt_einsum.enabled:                               \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 376 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m             \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 377 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# or the user has disabled using opt_einsum\u001b[0m                                \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m❱ \u001b[0m 378 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _VF.einsum(equation, operands)  \u001b[2m# type: ignore[attr-defined]\u001b[0m        \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 379 \u001b[0m\u001b[2m│   \u001b[0m                                                                               \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 380 \u001b[0m\u001b[2m│   \u001b[0mpath = \u001b[94mNone\u001b[0m                                                                    \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m   \u001b[2m 381 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m opt_einsum.is_available():                                                  \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `\u001b[1;35mcublasCreate\u001b[0m\u001b[1m(\u001b[0mhandle\u001b[1m)\u001b[0m`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit, cache = model.run_with_cache(\"Hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
