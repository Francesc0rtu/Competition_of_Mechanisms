{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../results')\n",
    "import json\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "base_dir = '../results/score_model/'\n",
    "\n",
    "# Regex pattern for matching file names\n",
    "pattern = r'gpt2_\\d+_evaluate_mechanism.csv'\n",
    "\n",
    "# Initialize an empty list to store file paths\n",
    "file_paths = []\n",
    "\n",
    "# Walk through the directory\n",
    "for dirname, _, filenames in os.walk(base_dir):\n",
    "    # Filter and append the files that match the pattern\n",
    "    file_paths.extend([os.path.join(dirname, filename) for filename in filenames if re.match(pattern, filename)])\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a DataFrame to store aggregated data\n",
    "aggregated_data = pd.DataFrame()\n",
    "\n",
    "# Loop over each file\n",
    "for file in file_paths:\n",
    "    # Read the current CSV file\n",
    "    current_data = pd.read_csv(file)\n",
    "\n",
    "    # If the aggregated_data DataFrame is empty, initialize it with the structure of the current_data\n",
    "    if aggregated_data.empty:\n",
    "        aggregated_data = current_data.copy()\n",
    "        # Initialize columns for mean and standard deviation\n",
    "        for column in [\"target_true\", \"target_false\", \"other\"]:\n",
    "            aggregated_data[column + \"_mean\"] = 0\n",
    "            aggregated_data[column + \"_std\"] = 0\n",
    "    else:\n",
    "        # For each column, calculate cumulative sum and square sum for standard deviation calculation\n",
    "        for column in [\"target_true\", \"target_false\", \"other\"]:\n",
    "            aggregated_data[column + \"_mean\"] += current_data[column]\n",
    "            aggregated_data[column + \"_std\"] += current_data[column]**2\n",
    "\n",
    "# Number of files\n",
    "num_files = len(file_paths)\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "for column in [\"target_true\", \"target_false\", \"other\"]:\n",
    "    aggregated_data[column + \"_mean\"] /= num_files\n",
    "    aggregated_data[column + \"_std\"] = (aggregated_data[column + \"_std\"] / num_files - aggregated_data[column + \"_mean\"]**2).apply(lambda x: x**0.5)\n",
    "\n",
    "# Drop the original columns and keep only mean and std columns\n",
    "aggregated_data.drop(columns=[\"target_true\", \"target_false\", \"other\"], inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>orthogonalize</th>\n",
       "      <th>target_true_mean</th>\n",
       "      <th>target_true_std</th>\n",
       "      <th>target_false_mean</th>\n",
       "      <th>target_false_std</th>\n",
       "      <th>other_mean</th>\n",
       "      <th>other_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>True</td>\n",
       "      <td>484.87</td>\n",
       "      <td>53.140692</td>\n",
       "      <td>8867.73</td>\n",
       "      <td>891.731987</td>\n",
       "      <td>547.40</td>\n",
       "      <td>59.100085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>True</td>\n",
       "      <td>820.94</td>\n",
       "      <td>86.762068</td>\n",
       "      <td>8333.54</td>\n",
       "      <td>838.392992</td>\n",
       "      <td>745.52</td>\n",
       "      <td>79.306933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>True</td>\n",
       "      <td>1096.42</td>\n",
       "      <td>113.592005</td>\n",
       "      <td>7885.51</td>\n",
       "      <td>793.288970</td>\n",
       "      <td>918.07</td>\n",
       "      <td>95.289585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>True</td>\n",
       "      <td>2260.58</td>\n",
       "      <td>230.114327</td>\n",
       "      <td>6549.26</td>\n",
       "      <td>659.798524</td>\n",
       "      <td>1090.16</td>\n",
       "      <td>113.496848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  orthogonalize  target_true_mean  target_true_std  \\\n",
       "0         gpt2           True            484.87        53.140692   \n",
       "1  gpt2-medium           True            820.94        86.762068   \n",
       "2   gpt2-large           True           1096.42       113.592005   \n",
       "3      gpt2-xl           True           2260.58       230.114327   \n",
       "\n",
       "   target_false_mean  target_false_std  other_mean   other_std  \n",
       "0            8867.73        891.731987      547.40   59.100085  \n",
       "1            8333.54        838.392992      745.52   79.306933  \n",
       "2            7885.51        793.288970      918.07   95.289585  \n",
       "3            6549.26        659.798524     1090.16  113.496848  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row with orthogonalize True\n",
    "gpt2_clean = pd.read_csv(\"../results/gpt2_evaluate_mechanism.csv\")\n",
    "gpt2_clean = gpt2_clean[gpt2_clean['orthogonalize'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data =aggregated_data.rename(columns={\"target_true_mean\": \"target_true\", \"target_false_mean\": \"target_false\", \"other_mean\":\"other\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding 0 for the standard deviation in the first dataset\n",
    "for column in [\"target_true\", \"target_false\", \"other\"]:\n",
    "    gpt2_clean[column + \"_std\"] = 0\n",
    "\n",
    "# Concatenate the two datasets\n",
    "final_dataset = pd.concat([gpt2_clean, aggregated_data], ignore_index=True)\n",
    "\n",
    "# Save the final dataset\n",
    "final_dataset.to_csv(\"../results/plot_data/gpt2_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"../results/plot_data/gpt2_count.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
