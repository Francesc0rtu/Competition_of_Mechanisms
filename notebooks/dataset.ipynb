{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fortu/miniconda3/envs/mpi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import json\n",
    "from src.model import WrapHookedTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial\n",
    "from transformer_lens import patching\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"known_1000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = WrapHookedTransformer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:00<00:00, 1903496.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for d in tqdm(data, total=len(data)):\n",
    "    dataset.append(\n",
    "        {\"prompt\": d[\"prompt\"],\n",
    "         \"target\": \" \" + d[\"attribute\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:38<00:00, 31.70it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_per_length = {}\n",
    "for d in tqdm(dataset, total=len(dataset)):\n",
    "    orthogonal_token = model.to_orthogonal_tokens(d[\"target\"])\n",
    "    d[\"premise\"] = d[\"prompt\"] + orthogonal_token + \" \" + d[\"prompt\"]\n",
    "    d[\"orthogonal_token\"] = orthogonal_token\n",
    "    d[\"length\"] = len(model.to_str_tokens(d[\"premise\"]))\n",
    "    if d[\"length\"] not in dataset_per_length:\n",
    "        dataset_per_length[d[\"length\"]] = []\n",
    "    dataset_per_length[d[\"length\"]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pytorch dataloader for each length\n",
    "dataloaders = {}\n",
    "for length in sorted(dataset_per_length.keys()):\n",
    "    dataloaders[length] = torch.utils.data.DataLoader(dataset_per_length[length], batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.62it/s]\n"
     ]
    }
   ],
   "source": [
    "target_probs_mean = {}\n",
    "orthogonal_probs_mean = {}\n",
    "target_win = {}\n",
    "orthogonal_win = {}\n",
    "other_win = {}\n",
    "target_win_over_orthogonal = {}\n",
    "target_win_over_orthogonal_dataset = []\n",
    "\n",
    "\n",
    "for length in sorted(dataset_per_length.keys()):\n",
    "    # get logits for each example\n",
    "    target_probs_mean[length] = []\n",
    "    orthogonal_probs_mean[length] = []\n",
    "    target_win[length] = 0\n",
    "    orthogonal_win[length] = 0\n",
    "    other_win[length] = 0\n",
    "    target_win_over_orthogonal[length] = 0\n",
    "    for batch in tqdm(dataloaders[length]):\n",
    "        logit = model(batch[\"premise\"])\n",
    "        probs = torch.softmax(logit, dim=-1)\n",
    "        batch_index = torch.arange(probs.shape[0])\n",
    "        target_probs = probs[batch_index, -1, model.to_tokens(batch[\"target\"], prepend_bos=False).squeeze(-1)]\n",
    "        orthogonal_probs = probs[batch_index, -1, model.to_tokens(batch[\"orthogonal_token\"], prepend_bos=False).squeeze(-1)]\n",
    "        predictions = probs[:,-1,:].max(dim=-1)[0]\n",
    "        # for each element of the batch check the prediction and update the win counter\n",
    "        for i in range(len(batch[\"premise\"])):\n",
    "            if target_probs[i] == predictions[i]:\n",
    "                target_win[length] += 1\n",
    "            elif orthogonal_probs[i] == predictions[i]:\n",
    "                orthogonal_win[length] += 1\n",
    "            if target_probs[i] > orthogonal_probs[i]:\n",
    "                target_win_over_orthogonal[length] += 1\n",
    "                target_win_over_orthogonal_dataset.append(batch[i])\n",
    "        \n",
    "        target_probs_mean[length].append(target_probs.mean().item())\n",
    "        orthogonal_probs_mean[length].append(orthogonal_probs.mean().item())\n",
    "    \n",
    "    # mean of logits for each length\n",
    "    target_probs_mean[length] = sum(target_probs_mean[length]) / len(target_probs_mean[length])\n",
    "    orthogonal_probs_mean[length] = sum(orthogonal_probs_mean[length]) / len(orthogonal_probs_mean[length])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target win 0.04052936311000827\n",
      "orthogonal win 0.7014061207609594\n",
      "other win 0.0\n"
     ]
    }
   ],
   "source": [
    "#sum target win and orthogonal win and target_win_over_orthogonal for each length\n",
    "target_win = sum(target_win.values())\n",
    "orthogonal_win = sum(orthogonal_win.values())\n",
    "\n",
    "#print percentages over the total number of examples\n",
    "print(\"target win\", target_win / len(dataset))\n",
    "print(\"orthogonal win\", orthogonal_win / len(dataset))\n",
    "target_win_over_orthogonal = sum(target_win_over_orthogonal.values())\n",
    "print(\"target win over orthogonal\", target_win_over_orthogonal / len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target win over orthogonal 0.1728701406120761\n"
     ]
    }
   ],
   "source": [
    "target_win_over_orthogonal = sum(target_win_over_orthogonal.values())\n",
    "print(\"target win over orthogonal\", target_win_over_orthogonal / len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(\"../data/counterfact.json\"))\n",
    "model = WrapHookedTransformer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21919/21919 [00:00<00:00, 206264.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for d in tqdm(data, total=len(data)):\n",
    "    for i in range(len(d[\"attribute_prompts\"])):\n",
    "        dataset.append(\n",
    "            {\"prompt\": d[\"attribute_prompts\"][i],\n",
    "             \"target\": \" \" + d[\"requested_rewrite\"][\"target_new\"][\"str\"]}\n",
    "        )\n",
    "    \n",
    "    for i in range(len(d[\"neighborhood_prompts\"])):\n",
    "        dataset.append(\n",
    "            {\"prompt\": d[\"neighborhood_prompts\"][i],\n",
    "             \"target\": \" \" + d[\"requested_rewrite\"][\"target_true\"][\"str\"]}\n",
    "        )\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random shuffle\n",
    "import random\n",
    "random.shuffle(dataset)\n",
    "dataset = dataset[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:58<00:00, 34.20it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_per_length = {}\n",
    "for d in tqdm(dataset, total=len(dataset)):\n",
    "    orthogonal_token = model.to_orthogonal_tokens(d[\"target\"])\n",
    "    d[\"premise\"] = d[\"prompt\"] + orthogonal_token + \" \" + d[\"prompt\"]\n",
    "    d[\"orthogonal_token\"] = orthogonal_token\n",
    "    d[\"length\"] = len(model.to_str_tokens(d[\"premise\"]))\n",
    "    if d[\"length\"] not in dataset_per_length:\n",
    "        dataset_per_length[d[\"length\"]] = []\n",
    "    dataset_per_length[d[\"length\"]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pytorch dataloader for each length\n",
    "dataloaders = {}\n",
    "for length in sorted(dataset_per_length.keys()):\n",
    "    dataloaders[length] = torch.utils.data.DataLoader(dataset_per_length[length], batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.34s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.84s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.79it/s]\n"
     ]
    }
   ],
   "source": [
    "target_probs_mean = {}\n",
    "orthogonal_probs_mean = {}\n",
    "target_win = {}\n",
    "orthogonal_win = {}\n",
    "other_win = {}\n",
    "target_win_over_orthogonal = {}\n",
    "target_win_dataset = []\n",
    "orthogonal_win_dataset = []\n",
    "\n",
    "\n",
    "for length in sorted(dataset_per_length.keys()):\n",
    "    # get logits for each example\n",
    "    target_probs_mean[length] = []\n",
    "    orthogonal_probs_mean[length] = []\n",
    "    target_win[length] = 0\n",
    "    orthogonal_win[length] = 0\n",
    "    other_win[length] = 0\n",
    "    target_win_over_orthogonal[length] = 0\n",
    "    for batch in tqdm(dataloaders[length]):\n",
    "        logit = model(batch[\"premise\"])\n",
    "        probs = torch.softmax(logit, dim=-1)\n",
    "        batch_index = torch.arange(probs.shape[0])\n",
    "        target_probs = probs[batch_index, -1, model.to_tokens(batch[\"target\"], prepend_bos=False).squeeze(-1)]\n",
    "        orthogonal_probs = probs[batch_index, -1, model.to_tokens(batch[\"orthogonal_token\"], prepend_bos=False).squeeze(-1)]\n",
    "        predictions = probs[:,-1,:].max(dim=-1)[0]\n",
    "        # for each element of the batch check the prediction and update the win counter\n",
    "        for i in range(len(batch[\"premise\"])):\n",
    "            if target_probs[i] == predictions[i]:\n",
    "                target_win[length] += 1\n",
    "                target_win_dataset.append(\n",
    "                    {\n",
    "                        \"prompt\": batch[\"prompt\"][i],\n",
    "                        \"target\": batch[\"target\"][i],\n",
    "                        \"premise\": batch[\"premise\"][i],\n",
    "                        \"orthogonal_token\": batch[\"orthogonal_token\"][i],\n",
    "                        \"length\": float(batch[\"length\"][i].cpu().detach().numpy().item()),\n",
    "                        \"target_probs\": float(target_probs[i].cpu().detach().numpy().item()),\n",
    "                        \"orthogonal_probs\": float(orthogonal_probs[i].cpu().detach().numpy().item()),\n",
    "                        \n",
    "                    }\n",
    "                \n",
    "                )\n",
    "            elif orthogonal_probs[i] == predictions[i]:\n",
    "                orthogonal_win[length] += 1\n",
    "                orthogonal_win_dataset.append(\n",
    "                    {\n",
    "                        \"prompt\": batch[\"prompt\"][i],\n",
    "                        \"target\": batch[\"target\"][i],\n",
    "                        \"premise\": batch[\"premise\"][i],\n",
    "                        \"orthogonal_token\": batch[\"orthogonal_token\"][i],\n",
    "                        \"length\": float(batch[\"length\"][i].cpu().detach().numpy().item()),\n",
    "                        \"target_probs\": float(target_probs[i].cpu().detach().numpy().item()),\n",
    "                        \"orthogonal_probs\": float(orthogonal_probs[i].cpu().detach().numpy().item()),\n",
    "                        \n",
    "                    }\n",
    "                \n",
    "                )\n",
    "            if target_probs[i] > orthogonal_probs[i]:\n",
    "                target_win_over_orthogonal[length] += 1\n",
    "                # target_win_over_orthogonal_dataset.append(batch[i])\n",
    "        \n",
    "        target_probs_mean[length].append(target_probs.mean().item())\n",
    "        orthogonal_probs_mean[length].append(orthogonal_probs.mean().item())\n",
    "    \n",
    "    # mean of logits for each length\n",
    "    target_probs_mean[length] = sum(target_probs_mean[length]) / len(target_probs_mean[length])\n",
    "    orthogonal_probs_mean[length] = sum(orthogonal_probs_mean[length]) / len(orthogonal_probs_mean[length])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target win 0.021\n",
      "orthogonal win 0.741\n",
      "target win over orthogonal 0.0845\n"
     ]
    }
   ],
   "source": [
    "#sum target win and orthogonal win and target_win_over_orthogonal for each length\n",
    "target_win = sum(target_win.values())\n",
    "orthogonal_win = sum(orthogonal_win.values())\n",
    "\n",
    "#print percentages over the total number of examples\n",
    "print(\"target win\", target_win / len(dataset))\n",
    "print(\"orthogonal win\", orthogonal_win / len(dataset))\n",
    "target_win_over_orthogonal = sum(target_win_over_orthogonal.values())\n",
    "print(\"target win over orthogonal\", target_win_over_orthogonal / len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(target_win_dataset, open(\"../data/target_win_dataset.json\", \"w\"), indent=4)\n",
    "json.dump(orthogonal_win_dataset, open(\"../data/orthogonal_win_dataset.json\", \"w\"), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
