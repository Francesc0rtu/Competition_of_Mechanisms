{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import json\n",
    "from src.model import WrapHookedTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial\n",
    "from transformer_lens import patching\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:00<00:00, 1509200.46it/s]\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(\"../data/known_1000.json\"))\n",
    "model = WrapHookedTransformer.from_pretrained(\"gpt2\")\n",
    "dataset = []\n",
    "for d in tqdm(data, total=len(data)):\n",
    "    dataset.append(\n",
    "        {\"prompt\": d[\"prompt\"],\n",
    "         \"target\": \" \" + d[\"attribute\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1209/1209 [00:33<00:00, 35.84it/s]\n",
      "100%|██████████| 13/13 [01:01<00:00,  4.74s/it]\n",
      "100%|██████████| 1209/1209 [00:40<00:00, 30.08it/s]\n",
      "100%|██████████| 13/13 [01:01<00:00,  4.73s/it]\n",
      "100%|██████████| 1209/1209 [00:39<00:00, 30.33it/s]\n",
      "100%|██████████| 13/13 [01:20<00:00,  6.23s/it]\n",
      "100%|██████████| 1209/1209 [00:40<00:00, 29.93it/s]\n",
      "100%|██████████| 13/13 [01:04<00:00,  4.97s/it]\n",
      "100%|██████████| 1209/1209 [00:41<00:00, 29.34it/s]\n",
      "100%|██████████| 13/13 [01:04<00:00,  4.96s/it]\n",
      "100%|██████████| 1209/1209 [00:41<00:00, 29.04it/s]\n",
      " 46%|████▌     | 6/13 [00:32<00:37,  5.38s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "alphas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "num_alphas = len(alphas)\n",
    "num_samples = 10\n",
    "\n",
    "# Initialize arrays\n",
    "target_win = np.zeros([num_alphas, num_samples])\n",
    "orthogonal_win = np.zeros([num_alphas, num_samples])\n",
    "target_win_over_orthogonal = np.zeros([num_alphas, num_samples])\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for sample in range(num_samples):\n",
    "        # Update dataset with orthogonal tokens and lengths\n",
    "        for d in tqdm(dataset, total=len(dataset)):\n",
    "            orthogonal_token = model.to_orthogonal_tokens(d[\"target\"], alpha=0.5)\n",
    "            d[\"premise\"] = d[\"prompt\"] + orthogonal_token + \" \" + d[\"prompt\"]\n",
    "            d[\"orthogonal_token\"] = orthogonal_token\n",
    "            d[\"length\"] = len(model.to_str_tokens(d[\"premise\"]))\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "        \n",
    "        target_win_for_sample = 0\n",
    "        orthogonal_win_for_sample = 0\n",
    "        target_win_over_orthogonal_for_sample = 0\n",
    "\n",
    "        for batch in tqdm(dataloader):\n",
    "            logit = model(batch[\"premise\"])\n",
    "            probs = torch.softmax(logit, dim=-1)\n",
    "            batch_index = torch.arange(probs.shape[0])\n",
    "            \n",
    "            target_tokens = model.to_tokens(batch[\"target\"], prepend_bos=False).squeeze(-1)\n",
    "            orthogonal_tokens = model.to_tokens(batch[\"orthogonal_token\"], prepend_bos=False).squeeze(-1)\n",
    "            \n",
    "            if len(orthogonal_tokens.shape) == 2:\n",
    "                orthogonal_tokens = orthogonal_tokens[:, 0]\n",
    "            \n",
    "            target_probs = probs[batch_index, -1, target_tokens]\n",
    "            orthogonal_probs = probs[batch_index, -1, orthogonal_tokens]\n",
    "            predictions = probs[:, -1, :].max(dim=-1)[0]\n",
    "\n",
    "            target_win_for_sample += (target_probs == predictions).sum().item()\n",
    "            orthogonal_win_for_sample += (orthogonal_probs == predictions).sum().item()\n",
    "            target_win_over_orthogonal_for_sample += (target_probs > orthogonal_probs).sum().item()\n",
    "\n",
    "        dataset_length = len(dataset)\n",
    "        target_win[i, sample] = target_win_for_sample / dataset_length\n",
    "        orthogonal_win[i, sample] = orthogonal_win_for_sample / dataset_length\n",
    "        target_win_over_orthogonal[i, sample] = target_win_over_orthogonal_for_sample / dataset_length\n",
    "\n",
    "print(target_win.mean(axis=1), target_win.std(axis=1))\n",
    "print(orthogonal_win.mean(axis=1), orthogonal_win.std(axis=1))\n",
    "print(target_win_over_orthogonal.mean(axis=1), target_win_over_orthogonal.std(axis=1))\n",
    "\n",
    "# Save the results\n",
    "np.save(\"target_win.npy\", target_win)\n",
    "np.save(\"orthogonal_win.npy\", orthogonal_win)\n",
    "np.save(\"target_win_over_orthogonal.npy\", target_win_over_orthogonal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
